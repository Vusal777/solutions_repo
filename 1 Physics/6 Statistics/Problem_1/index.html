<!DOCTYPE html>

<html class="writer-html5" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<link href="../../../img/favicon.ico" rel="shortcut icon"/>
<title>Problem 1 - Physics and Mathematics</title>
<link href="../../../css/theme.css" rel="stylesheet"/>
<link href="../../../css/theme_extra.css" rel="stylesheet"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" rel="stylesheet"/>
<script>
        // Current page data
        var mkdocs_page_name = "Problem 1";
        var mkdocs_page_input_path = "1 Physics/6 Statistics/Problem_1.md";
        var mkdocs_page_url = null;
      </script>
<!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/yaml.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/rust.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/python.min.js"></script>
<script>hljs.highlightAll();</script>
</head>
<body class="wy-body-for-nav" role="document">
<div class="wy-grid-for-nav">
<nav class="wy-nav-side stickynav" data-toggle="wy-nav-shift">
<div class="wy-side-scroll">
<div class="wy-side-nav-search">
<a class="icon icon-home" href="../../.."> Physics and Mathematics
        </a><div role="search">
<form action="../../../search.html" class="wy-form" id="rtd-search-form" method="get">
<input aria-label="Search docs" name="q" placeholder="Search docs" title="Type search term here" type="text"/>
</form>
</div>
</div>
<div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../..">Introduction</a>
</li>
</ul>
<p class="caption"><span class="caption-text">1 Physics</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal">1 Mechanics</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../1%20Mechanics/Problem_1/">Investigating the Range as a Function of the Angle of Projection</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../1%20Mechanics/Problem_2/">Investigating the Dynamics of a Forced Damped Pendulum</a>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal">2 Gravity</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../2%20Gravity/Problem_1/">Orbital Period and Orbital Radius: Understanding Keplerâ€™s Third Law</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../2%20Gravity/Problem_2/">Escape Velocities and Cosmic Velocities</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../2%20Gravity/Problem_3/">Trajectories of a Freely Released Payload Near Earth</a>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal">3 Waves</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../3%20Waves/Problem_1/">Interference Patterns on a Water Surface: A Deep Dive into Wave Superposition</a>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal">4 Electromagnetism</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../4%20Electromagnetism/Problem_1/">Simulating the Effects of the Lorentz Force</a>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal">5 Circuits</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../5%20Circuits/Problem_1/">Equivalent Resistance Using Graph Theory</a>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal current">6 Statistics</a>
<ul class="current">
<li class="toctree-l2 current"><a class="reference internal current" href="#">Problem 1</a>
<ul class="current">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../Problem_2/">Problem 2</a>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal">7 Measurements</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../7%20Measurements/Problem_1/">Problem 1</a>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">2 Mathematics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../2%20Mathematics/1%20Linear_algebra/">Linear Algebra</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../2%20Mathematics/2%20Analytic_geometry/">Analytic geometry</a>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../2%20Mathematics/3%20Calculus/">Calculus</a>
</li>
</ul>
<p class="caption"><span class="caption-text">3 Discret Mathematics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal">1 Set Theory and ...</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../../3%20Discret_Mathematics/1%20Set%20Theory%20and%20.../_02%20Set_Theory/">Set Theory</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../3%20Discret_Mathematics/1%20Set%20Theory%20and%20.../_03%20Relations/">Relations</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../3%20Discret_Mathematics/1%20Set%20Theory%20and%20.../_04%20Functions/">Functions</a>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal">2 Number Theory and ...</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../../3%20Discret_Mathematics/2%20Number%20Theory%20and%20.../_05%20Combinatorics/">Combinatorics</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../3%20Discret_Mathematics/2%20Number%20Theory%20and%20.../_08%20Number_Theory/">Number Theory</a>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal">3 Recurrence and ...</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../../3%20Discret_Mathematics/3%20Recurrence%20and%20.../_06%20Sequences_and_Series/">Sequences and Series</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../3%20Discret_Mathematics/3%20Recurrence%20and%20.../_07%20Induction/">Induction</a>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../3%20Discret_Mathematics/3%20Recurrence%20and%20.../_09%20Recurrence/">Recurrence</a>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal">4 Graph Theory and ...</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../../3%20Discret_Mathematics/4%20Graph%20Theory%20and%20.../_10%20Graph_Theory/">Graph Theory</a>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal">5 Logic</a>
<ul>
<li class="toctree-l2"><a class="reference internal" href="../../../3%20Discret_Mathematics/5%20Logic/_01%20Logic/">Logic</a>
</li>
</ul>
</li>
</ul>
</div>
</div>
</nav>
<section class="wy-nav-content-wrap" data-toggle="wy-nav-shift">
<nav aria-label="Mobile navigation menu" class="wy-nav-top" role="navigation">
<i class="fa fa-bars" data-toggle="wy-nav-top"></i>
<a href="../../..">Physics and Mathematics</a>
</nav>
<div class="wy-nav-content">
<div class="rst-content"><div aria-label="breadcrumbs navigation" role="navigation">
<ul class="wy-breadcrumbs">
<li><a aria-label="Docs" class="icon icon-home" href="../../.."></a></li>
<li class="breadcrumb-item">1 Physics</li>
<li class="breadcrumb-item">6 Statistics</li>
<li class="breadcrumb-item active">Problem 1</li>
<li class="wy-breadcrumbs-aside">
</li>
</ul>
<hr/>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div class="section" itemprop="articleBody">
<h1 id="problem-1">Problem 1</h1>
<h1 id="exploring-the-central-limit-theorem-clt-through-simulations">Exploring the Central Limit Theorem (CLT) Through Simulations</h1>
<hr/>
<h2 id="1-introduction">1. Introduction</h2>
<p>The <strong>Central Limit Theorem (CLT)</strong> is one of the most profound results in probability theory and statistics. It states that the sampling distribution of the sample mean of a sufficiently large number of independent, identically distributed (i.i.d.) random variables, each with finite mean and variance, will approximate a normal (Gaussian) distribution, regardless of the original distribution of the variables.</p>
<p>This surprising and powerful result explains why the normal distribution arises so frequently in natural phenomena, manufacturing processes, finance, physics, and social sciences. </p>
<p>In this study, we will:
- Explore the CLT both theoretically and empirically.
- Perform detailed simulations on various distributions.
- Analyze how sample size, original distribution shape, and variance influence convergence.
- Provide practical interpretations of the CLT in real-world contexts.</p>
<hr/>
<h2 id="2-theoretical-background">2. Theoretical Background</h2>
<h3 id="21-formal-statement-of-clt">2.1. Formal Statement of CLT</h3>
<p>Let <span class="arithmatex">\( X_1, X_2, \ldots, X_n \)</span> be a sequence of i.i.d. random variables with expected value <span class="arithmatex">\( \mathbb{E}[X_i] = \mu \)</span> and variance <span class="arithmatex">\( \text{Var}(X_i) = \sigma^2 \)</span>. Define the sample mean:</p>
<div class="arithmatex">\[
\bar{X}_n = \frac{1}{n}\sum_{i=1}^{n} X_i
\]</div>
<p>Then the standardized sample mean:</p>
<div class="arithmatex">\[
Z_n = \frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}
\]</div>
<p>converges in distribution to a standard normal random variable <span class="arithmatex">\( \mathcal{N}(0,1) \)</span> as <span class="arithmatex">\( n \to \infty \)</span>.</p>
<hr/>
<h3 id="22-intuition-behind-the-clt">2.2. Intuition Behind the CLT</h3>
<p>The idea is that while individual random variables may behave irregularly, their <strong>average</strong> over many trials stabilizes into a predictable bell-shaped curve. This stabilization occurs even if the original data are skewed, discrete, or have a bounded range.</p>
<hr/>
<h3 id="23-importance-in-statistics">2.3. Importance in Statistics</h3>
<ul>
<li>Justifies using normal-based confidence intervals and hypothesis tests even for non-normal populations.</li>
<li>Forms the foundation of inferential techniques.</li>
<li>Enables error analysis in physical experiments and quality control.</li>
</ul>
<hr/>
<h2 id="3-simulation-strategy">3. Simulation Strategy</h2>
<p>To deepen understanding, we simulate three different types of populations:</p>
<ul>
<li>A <strong>uniform distribution</strong> (bounded and symmetric).</li>
<li>An <strong>exponential distribution</strong> (unbounded and highly skewed).</li>
<li>A <strong>binomial distribution</strong> (discrete and symmetric).</li>
</ul>
<p>For each, we will:</p>
<ol>
<li>Generate a large synthetic "population."</li>
<li>Draw random samples of various sizes (e.g., <span class="arithmatex">\( n = 5, 10, 30, 50, 100 \)</span>).</li>
<li>Calculate sample means across multiple iterations.</li>
<li>Visualize the empirical distribution of the sample means.</li>
<li>Analyze how the sample size affects convergence to normality.</li>
</ol>
<hr/>
<h2 id="4-population-creation">4. Population Creation</h2>
<p>First, we create large datasets representing each population:</p>
<pre><code class="language-python">import numpy as np

np.random.seed(42)

# Populations
population_uniform = np.random.uniform(0, 1, size=100000)
population_exponential = np.random.exponential(scale=1.0, size=100000)
population_binomial = np.random.binomial(n=10, p=0.5, size=100000)
</code></pre>
<hr/>
<h2 id="5-sampling-and-visualization">5. Sampling and Visualization</h2>
<p>We now perform repeated random sampling, compute sample means, and plot their distributions.</p>
<pre><code class="language-python">import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import norm

def simulate_sampling(population, label):
    sample_sizes = [5, 10, 30, 50, 100]
    fig, axs = plt.subplots(1, len(sample_sizes), figsize=(24, 4))

    for idx, n in enumerate(sample_sizes):
        means = [np.mean(np.random.choice(population, size=n)) for _ in range(5000)]
        sns.histplot(means, bins=30, kde=True, stat="density", ax=axs[idx], color="cornflowerblue")
        mu, sigma = np.mean(means), np.std(means)
        x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)
        axs[idx].plot(x, norm.pdf(x, mu, sigma), 'r--')
        axs[idx].set_title(f'{label}\nn={n}')
    plt.tight_layout()
    plt.show()

simulate_sampling(population_uniform, "Uniform(0,1)")
simulate_sampling(population_exponential, "Exponential(Î»=1)")
simulate_sampling(population_binomial, "Binomial(n=10, p=0.5)")
</code></pre>
<hr/>
<h2 id="6-results-and-analysis">6. Results and Analysis</h2>
<h3 id="61-uniform-distribution-results">6.1. Uniform Distribution Results</h3>
<ul>
<li>At <span class="arithmatex">\( n = 5 \)</span>, the sample mean already shows some bell shape.</li>
<li>By <span class="arithmatex">\( n = 30 \)</span>, the sampling distribution is almost perfectly normal.</li>
<li>Because the original distribution is symmetric and bounded, convergence is <strong>rapid</strong>.</li>
</ul>
<hr/>
<h3 id="62-exponential-distribution-results">6.2. Exponential Distribution Results</h3>
<ul>
<li>At small sample sizes (<span class="arithmatex">\( n = 5 \)</span>), the distribution of means is still skewed.</li>
<li>At <span class="arithmatex">\( n = 30 \)</span>, the skewness begins to disappear.</li>
<li>By <span class="arithmatex">\( n = 100 \)</span>, the sampling distribution approximates a normal very closely.</li>
<li>This case highlights how <strong>more skewed original distributions require larger <span class="arithmatex">\( n \)</span></strong> for CLT effects to dominate.</li>
</ul>
<hr/>
<h3 id="63-binomial-distribution-results">6.3. Binomial Distribution Results</h3>
<ul>
<li>Even for <span class="arithmatex">\( n = 5 \)</span>, the sample means appear roughly symmetric.</li>
<li>At <span class="arithmatex">\( n = 30 \)</span> and higher, convergence to normality is excellent.</li>
<li>Since the binomial distribution with <span class="arithmatex">\( p = 0.5 \)</span> is nearly symmetric and discrete, convergence is <strong>fast</strong>.</li>
</ul>
<hr/>
<h2 id="7-quantitative-investigation-variance-behavior">7. Quantitative Investigation: Variance Behavior</h2>
<p>The theory predicts that:</p>
<div class="arithmatex">\[
\text{Var}(\bar{X}_n) = \frac{\sigma^2}{n}
\]</div>
<p>Letâ€™s verify this numerically.</p>
<pre><code class="language-python">def study_variance(population):
    sample_sizes = np.array([5, 10, 30, 50, 100])
    variances = []
    for n in sample_sizes:
        sample_means = [np.mean(np.random.choice(population, size=n)) for _ in range(5000)]
        variances.append(np.var(sample_means))
    return sample_sizes, variances

sizes, var_uniform = study_variance(population_uniform)
sizes, var_exponential = study_variance(population_exponential)
sizes, var_binomial = study_variance(population_binomial)

plt.loglog(sizes, var_uniform, 'o-', label='Uniform')
plt.loglog(sizes, var_exponential, 's-', label='Exponential')
plt.loglog(sizes, var_binomial, '^-', label='Binomial')
plt.loglog(sizes, 1/sizes, 'k--', label='Reference 1/n')
plt.xlabel('Sample Size (n)')
plt.ylabel('Variance of Sample Mean')
plt.title('Variance Shrinking with Sample Size (Log-Log Plot)')
plt.legend()
plt.grid(True, which="both")
plt.show()
</code></pre>
<p>The empirical results confirm that variance decreases proportionally to <span class="arithmatex">\( 1/n \)</span>.</p>
<hr/>
<h2 id="8-additional-examples">8. Additional Examples</h2>
<h3 id="81-physical-measurement-errors">8.1. Physical Measurement Errors</h3>
<p>When measuring a physical quantity (e.g., mass of an object) multiple times, individual measurements can fluctuate due to random error. By the CLT, the average of these measurements will be approximately normally distributed, allowing for easy error estimation.</p>
<hr/>
<h3 id="82-financial-returns">8.2. Financial Returns</h3>
<p>In finance, daily returns on a stock are highly variable. However, the average return over many days tends toward normality, making techniques like Value at Risk (VaR) or Black-Scholes modeling mathematically justifiable.</p>
<hr/>
<h3 id="83-manufacturing-quality-control">8.3. Manufacturing Quality Control</h3>
<p>Suppose a factory produces resistors with slight variations. If we measure the resistance of randomly selected batches and average them, the batch mean will follow a normal distribution, allowing the company to set quality thresholds using normal probability calculations.</p>
<hr/>
<h2 id="9-practical-implications">9. Practical Implications</h2>
<p>The CLT is not just a theoretical result:
- <strong>Confidence intervals</strong> for unknown means can be constructed assuming normality.
- <strong>Hypothesis testing</strong> about means and differences of means relies on normal approximation.
- <strong>Large sample methods</strong> (even for complicated statistics) assume that the statistic is approximately normal.</p>
<p>Thus, the CLT enables efficient inference in situations where the original data distribution might be unknown, complex, or skewed.</p>
<hr/>
<h2 id="10-limitations-and-cautions">10. Limitations and Cautions</h2>
<p>While the CLT is powerful, it has limitations:
- The original data must have <strong>finite variance</strong>.
- Very <strong>heavy-tailed</strong> distributions (like Cauchy) do not satisfy classical CLT assumptions.
- <strong>Dependence</strong> between observations can invalidate the theorem unless handled properly.
- The rate of convergence varies: heavily skewed or kurtotic distributions require larger <span class="arithmatex">\( n \)</span>.</p>
<hr/>
<h3 id="monte-carlo-simulation-for-random-walks">Monte Carlo Simulation for Random Walks</h3>
<p>A <strong>random walk</strong> is a process where each step is independent, and each step is drawn from a random distribution, such as <span class="arithmatex">\(\pm 1\)</span>. By simulating many such random walks, we can calculate the average displacement at each step and observe how the distribution of these averages converges to a normal distribution.</p>
<p>Hereâ€™s how to implement this using Python:</p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Set random seed for reproducibility
np.random.seed(42)

# Parameters for the simulation
n_walks = 5000  # number of random walks
n_steps = 100  # steps per walk

# Simulating random walks
walks = np.random.choice([-1, 1], size=(n_walks, n_steps))
displacements = np.cumsum(walks, axis=1)

# Now, calculate the sample mean for each walk at each step
sample_means = np.mean(displacements, axis=0)

# Visualizing the results
plt.figure(figsize=(12, 6))

# Plotting the distribution of the sample means after each step
sns.histplot(sample_means, kde=True, bins=30, stat="density", color="cornflowerblue")

# Add a normal distribution curve for comparison
mu, sigma = np.mean(sample_means), np.std(sample_means)
x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)
plt.plot(x, 1/(sigma * np.sqrt(2 * np.pi)) * np.exp(-(x - mu)**2 / (2 * sigma**2)), 'r--', label="Normal Approximation")

plt.title("Monte Carlo Simulation: Distribution of Sample Means (Random Walk)")
plt.xlabel("Sample Mean")
plt.ylabel("Density")
plt.legend()
plt.grid(True)
plt.show()
</code></pre>
<h3 id="explanation">Explanation:</h3>
<ol>
<li>
<p><strong>Random Walk Simulation</strong>: We simulate <span class="arithmatex">\(5000\)</span> random walks, each of length <span class="arithmatex">\(100\)</span>. At each step, the walker moves randomly either <span class="arithmatex">\(+1\)</span> or <span class="arithmatex">\(-1\)</span>.</p>
</li>
<li>
<p><strong>Cumulative Sum</strong>: The displacement after each step is calculated using <code>np.cumsum</code> (cumulative sum of steps).</p>
</li>
<li>
<p><strong>Sample Means</strong>: For each walk, we calculate the mean displacement after each step, which forms the basis for our "sample mean."</p>
</li>
<li>
<p><strong>Visualization</strong>: We plot a histogram of the sample means after each step and overlay a normal distribution for comparison.</p>
</li>
</ol>
<h3 id="results-interpretation">Results Interpretation:</h3>
<ul>
<li>At the beginning (with fewer steps), the distribution of sample means will be <strong>non-normal</strong>, reflecting the randomness and the small sample size.</li>
<li>As the number of steps increases, the distribution of the sample means will converge to a <strong>normal distribution</strong>, demonstrating the Central Limit Theorem in action.</li>
</ul>
<p>This Monte Carlo approach visually reinforces the concept that regardless of the walk's randomness, the average over many walks follows a Gaussian distribution as the number of steps grows.</p>
<p>Would you like me to add more features or explanations for this simulation?</p>
<h2 id="11-conclusion">11. Conclusion</h2>
<p>Through both theoretical exposition and detailed computational experiments, the Central Limit Theorem has been demonstrated as a universal and indispensable result in probability theory. Our simulations showed that even populations with highly non-normal shapes lead to normally distributed sample means when the sample size becomes large.</p>
<p>Understanding the CLT provides crucial insight into statistical modeling, scientific experimentation, and quality assurance across various fields.</p>
</div>
</div><footer>
<div aria-label="Footer Navigation" class="rst-footer-buttons" role="navigation">
<a class="btn btn-neutral float-left" href="../../5%20Circuits/Problem_1/" title="Equivalent Resistance Using Graph Theory"><span class="icon icon-circle-arrow-left"></span> Previous</a>
<a class="btn btn-neutral float-right" href="../Problem_2/" title="Problem 2">Next <span class="icon icon-circle-arrow-right"></span></a>
</div>
<hr/>
<div role="contentinfo">
<!-- Copyright etc -->
</div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
</div>
</div>
</section>
</div>
<div aria-label="Versions" class="rst-versions" role="note">
<span class="rst-current-version" data-toggle="rst-current-version">
<span><a href="../../5%20Circuits/Problem_1/" style="color: #fcfcfc">Â« Previous</a></span>
<span><a href="../Problem_2/" style="color: #fcfcfc">Next Â»</a></span>
</span>
</div>
<script src="../../../js/jquery-3.6.0.min.js"></script>
<script>var base_url = "../../..";</script>
<script src="../../../js/theme_extra.js"></script>
<script src="../../../js/theme.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script src="../../../search/main.js"></script>
<script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>
</body>
</html>
